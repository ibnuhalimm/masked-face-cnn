{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyMx4xAq3Vb4KK9J/M/ga+Y+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zszVT0zzrCCg"},"outputs":[],"source":["import os\n","import shutil\n","\n","if os.path.isfile(\"masked-face-dataset.zip\"):\n","  os.remove('masked-face-dataset.zip')\n","  \n","if os.path.exists(\"masked-face-dataset\"):\n","  shutil.rmtree('masked-face-dataset')\n","\n","!wget https://storage.googleapis.com/ib-ml-bucket/masked-face-dataset.zip\n","!unzip 'masked-face-dataset.zip'"]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","test_data_filename = 'masked-face-test-v2';\n","\n","if os.path.isfile(f'{test_data_filename}.zip'):\n","  os.remove(f'{test_data_filename}.zip')\n","\n","if os.path.exists(f'{test_data_filename}'):\n","  shutil.rmtree(f'{test_data_filename}')\n","\n","!wget https://storage.googleapis.com/ib-ml-bucket/masked-face-test-v2.zip\n","!unzip masked-face-test-v2.zip"],"metadata":{"id":"ktNLqXvUYt8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","# try:\n","#   resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n","#   tf.config.experimental_connect_to_cluster(resolver)\n","#   tf.tpu.experimental.initialize_tpu_system(resolver)\n","#   print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","#   strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","# except ValueError:\n","#   strategy = tf.distribute.get_strategy() \n"],"metadata":{"id":"GY7FIH_FytnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.vgg16 import preprocess_input\n","import pathlib\n","import numpy as np\n","\n","dataset_root_dir = 'masked-face-dataset'\n","test_case = f'{dataset_root_dir}/cloth/full_face'\n","\n","train_dir = f'{test_case}/train'\n","validation_dir = f'{test_case}/validation'\n","\n","img_width = 256\n","img_height = 256\n","batch_size_train = 8\n","batch_size_val = 8\n","\n","# Get the class names\n","data_dir = pathlib.Path(train_dir)\n","class_names = np.array(sorted(item.name for item in data_dir.glob('*')))\n","\n","# Preprocessing the data (scaling/normalization)\n","train_datagen = ImageDataGenerator(rescale=1.0/255)\n","validation_datagen = ImageDataGenerator(rescale=1.0/255)\n","\n","# Import data from directories and turn in into batches\n","train_data = train_datagen.flow_from_directory(directory=train_dir,\n","                                               target_size=(img_width, img_height),\n","                                               class_mode=\"categorical\",\n","                                               batch_size=batch_size_train,\n","                                               shuffle=True)\n","\n","validation_data = validation_datagen.flow_from_directory(directory=validation_dir,\n","                                                         target_size=(img_width, img_height),\n","                                                         class_mode=\"categorical\",\n","                                                         batch_size=batch_size_train,\n","                                                         shuffle=True)\n","\n","train_data_gen_augmented = ImageDataGenerator(rescale=1/255.,\n","                                              rotation_range=10,\n","                                              zoom_range=.2,\n","                                              # width_shift_range=.2,\n","                                              # height_shift_range=.2,\n","                                              # fill_mode=\"constant\",\n","                                              horizontal_flip=True,\n","                                              # vertical_flip=True,\n","                                              # shear_range=0.1,\n","                                              preprocessing_function=preprocess_input\n","                                              )\n","\n","# Better result with batch_size = 8\n","train_data_augmented = train_data_gen_augmented.flow_from_directory(directory=train_dir,\n","                                                                    target_size=(img_width, img_height),\n","                                                                    class_mode=\"categorical\",\n","                                                                    batch_size=batch_size_val)"],"metadata":{"id":"rcceXmGEtQVT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.applications.vgg16 import VGG16\n","from keras.layers import Dense, Input, Flatten, Dropout\n","from keras.models import Model\n","\n","def model_VGG16():\n","    # Load the VGG16 model\n","    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n","\n","    # Freeze all layers\n","    for layer in vgg16.layers:\n","        layer.trainable = False\n","\n","    # Build new classifier\n","    x = vgg16.output\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu')(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(rate=0.1)(x)\n","    x = Dense(len(class_names), activation='softmax')(x)\n","\n","    # Create new model\n","    return Model(inputs=vgg16.input, outputs=x)"],"metadata":{"id":"386kPejNvfJn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.optimizers import Adam\n","\n","model = model_VGG16()\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=Adam(learning_rate=1e-4),\n","              metrics=[\"accuracy\"])\n","model_summary = model.summary()"],"metadata":{"id":"RBI7K-9MvlC1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","start_history = time.perf_counter()\n","\n","# model = load_model(filepath='./model')\n","# steps_per_epoch = round((len(train_data_augmented) / batch_size_train))\n","steps_per_epoch = 64\n","\n","history = model.fit(train_data_augmented,\n","                    epochs=60,\n","                    steps_per_epoch=steps_per_epoch,\n","                    validation_data=validation_data,\n","                    validation_steps=batch_size_val)\n","\n","elapsed_history = time.perf_counter() - start_history"],"metadata":{"id":"I4liJuZvvzGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_accuracy = model.evaluate(train_data_augmented)\n","print(f'Training Loss : {train_accuracy[0]}')\n","print(f'Training Accuracy : {round(train_accuracy[1] * 100, 2)}%\\n')\n","\n","val_accuracy = model.evaluate(validation_data)\n","print(f'Validation Loss : {val_accuracy[0]}')\n","print(f'Validation Accuracy : {round(val_accuracy[1] * 100, 2)}%')"],"metadata":{"id":"jDiStMvjv3Hy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import load_img\n","import matplotlib.image as mpimpg\n","import matplotlib.pyplot as plt\n","import glob\n","\n","faceimagedir = test_data_filename\n","\n","images = []\n","images_paths = []\n","for img_path in glob.glob(faceimagedir + '/*.jpg'):\n","    images.append(mpimpg.imread(img_path))\n","    images_paths.append(img_path)\n","    \n","plt.figure(figsize=(14, 8))\n","columns = 6\n","\n","for i, image in enumerate(images):\n","    img = load_img(images_paths[i], target_size=(img_width, img_height))\n","\n","    image_to_predict = np.expand_dims(img, axis=0)\n","    predictions = model.predict(image_to_predict)\n","    classes = np.argmax(predictions, axis = 1)\n","    \n","    rows = int(len(images) / columns + 1)\n","    plt.subplot(rows, columns, i + 1)\n","    # plt.text(4, 58, class_names[classes][0], bbox={'facecolor': 'white', 'pad': 3})\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.xlabel(class_names[classes][0])\n","    # plt.xlabel(predictions)\n","    plt.imshow(img)"],"metadata":{"id":"2DYgDdyTYlFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","img, label = train_data_augmented.next()\n","\n","plt.figure(figsize=(15, 8))\n","\n","# generate batch of images\n","for i in range(0, 5):\n","    # fig = plt.figure()\n","    plt.subplot(1, 5, 1 + i)\n","    # ax.set_title()\n","    plt.imshow(img[i])\n","\n","plt.show()"],"metadata":{"id":"UeLhJH4UJs08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create directory to save the result\n","test_time = time.strftime('%Y%m%d_%H%M')\n","result_dir = f'results/{test_case}/{test_time}'\n","if (os.path.exists(result_dir) == False):\n","        os.makedirs(result_dir)\n","        \n","## Write History Time and Evaluate into a txt file\n","f = open(f'{result_dir}/result_data.txt', 'a')\n","\n","f.write('- fit time \\t: %.3f seconds' % elapsed_history)\n","f.write('\\n\\n')\n","\n","f.write(f'- image_width \\t: {img_width}')\n","f.write(f'- image_height \\t: {img_height}')\n","f.write('\\n\\n')\n","\n","f.write(f'- steps per epoch \\t: {steps_per_epoch}')\n","f.write(f'- train batch size \\t: {batch_size_train}')\n","f.write(f'- val batch size \\t: {batch_size_val}')\n","f.write('\\n\\n')\n","\n","f.write('- train_loss \\t: %.5f\\n' % train_accuracy[0])\n","f.write(\"- train_acc \\t: {:.2%}\".format(train_accuracy[1]))\n","f.write('\\n\\n')\n","\n","f.write('- val_loss \\t: %.5f\\n' % val_accuracy[0])\n","f.write(\"- val_acc \\t: {:.2%}\".format(val_accuracy[1]))\n","f.close()\n","\n","\n","# Save the model\n","str_percentage = str(round(val_accuracy[1] * 100, 2))\n","# model_filename = \"model_\" + test_case + \"_\" + str_percentage.replace('.', '_')\n","model_filename = \"model\"\n","model_json = model.to_json()\n","with open(f'{result_dir}/{model_filename}.json', \"w\") as json_file:\n","    json_file.write(f'{result_dir}/{model_json}')\n","\n","# model.save_weights(f'{result_dir}/{model_filename}_weight.h5')\n","model.save(f'{result_dir}/{model_filename}', save_format='h5')"],"metadata":{"id":"A-UgNDgYIx4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_loss_curves(history):\n","    \"\"\"\n","    Plots the loss curves from the training history.\n","    \"\"\"\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model Loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    # plt.show()\n","\n","    return plt\n","\n","def plot_accuracy_curves(history):\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('Model Accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'val'], loc='upper left')\n","    # plt.show()\n","\n","    return plt"],"metadata":{"id":"cVVFFEAdh08V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_plot = plot_loss_curves(history)\n","loss_plot.savefig(f'{result_dir}/loss_graph.svg')"],"metadata":{"id":"E_rifxYCh2Sn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc_plot = plot_accuracy_curves(history)\n","acc_plot.savefig(f'{result_dir}/acc_graph.svg')"],"metadata":{"id":"xryVFNDIlrEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from keras.utils import load_img\n","# img = load_img('masked-face-test/ibnu_01.jpg', target_size=(img_width, img_height))\n","\n","# image_to_predict = np.expand_dims(img, axis=0)\n","# predictions = model.predict(image_to_predict)\n","# classes = np.argmax(predictions, axis = 1)\n","# print(predictions)"],"metadata":{"id":"cAWdj2O9gioM"},"execution_count":null,"outputs":[]}]}